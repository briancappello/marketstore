
**Output:**
```
task_id: ses_39d0450abffel4omPWaKUTgBRG (for resuming to continue this task if needed)

<task_result>
Now I have all the information needed. Here is a comprehensive summary of everything found.

---

## Complete Findings: MarketStore Configuration & Plugins

### 1. Example `mkts.yml` Configuration Files

**A) Default template** (generated by `marketstore init`)
- **File**: `/home/brian/dev/marketstore/cmd/create/default.yml`
- This is embedded and written to `./mkts.yml` by the `create` command.

```yaml
root_directory: data
listen_port: 5993
grpc_listen_port: 5995
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
# timezone: "America/New_York"
# utilities_url: "localhost:5994"
#
# triggers:
#   - module: ondiskagg.so
#     on: "*/1Min/OHLCV"
#     config:
#       destinations:
#         - 5Min
#         - 15Min
#         - 1H
#         - 1D
#   - module: stream.so
#     on: "*/*/*"
#     config:
#       filter: nasdaq
#
# bgworkers:
#   - module: gdaxfeeder.so
#     name: GdaxFetcher
#     config:
#       query_start: "2017-09-01 00:00"
```

**B) Integration test config**
- **File**: `/home/brian/dev/marketstore/tests/integ/bin/mkts.yml`

```yaml
root_directory: /project/data/mktsdb
listen_port: 5993
grpc_listen_port: 5995
polling_interval: 60
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
start_time: 2016-09-15 13:45
disable_variable_compression: true
```

**C) Replication master config**
- **File**: `/home/brian/dev/marketstore/tests/replication/config/mkts-master.yml`

```yaml
root_directory: /project/data/mktsdb
listen_port: 5996
grpc_listen_port: 5997
polling_interval: 60
log_level: debug
stop_grace_period: 0
wal_rotate_interval: 5
start_time: 2016-09-15 13:45
replication:
  enabled: true
  listen_port: 5998
```

**D) Replication replica config**
- **File**: `/home/brian/dev/marketstore/tests/replication/config/mkts-replica.yml`

```yaml
root_directory: /project/data/mktsdb
listen_port: 5999
grpc_listen_port: 6000
polling_interval: 60
log_level: debug
stop_grace_period: 0
wal_rotate_interval: 5
start_time: 2016-09-15 13:45
replication:
  master_host: "replication_tests_mstore_master:5998"
```

**E) Test config**
- **File**: `/home/brian/dev/marketstore/test_config.yaml`

```yaml
root_directory: ./data
listen_port: 5993
grpc_listen_port: 5995
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
start_time: 2024-01-01 00:00:00
```

**F) Massive plugin example** (most complete real-world example)
- **File**: `/home/brian/dev/marketstore/contrib/massive/mkts.example.yml`

```yaml
root_directory: data
listen_port: 5993
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
enable_last_known: false
timezone: "America/New_York"
triggers:
  - module: ondiskagg.so
    on: "*/1Min/OHLCV"
    config:
      filter: nasdaq
      destinations: [ '5Min', '15Min', '1H', '1D' ]
bgworkers:
  - module: massive.so
    name: Massive
    config:
      api_key: your_massive_api_key
      base_url: https://api.massive.com
      ws_server: wss://socket.massive.com
      data_types: [ 'bars' ]
      symbols:
        - AAPL
        - SPY
      query_start: "2024-01-01"
      backfill_batch_size: 50000
      backfill_adjusted: true
```

**G) Polygon plugin example**
- **File**: `/home/brian/dev/marketstore/contrib/polygon/mkts.example.yml`

**H) IEX plugin example**
- **File**: `/home/brian/dev/marketstore/contrib/iex/mkts.example.yml`

**I) Alpaca plugin example**
- **File**: `/home/brian/dev/marketstore/contrib/alpaca/mkts.example.yml`

**J) Binance Feeder V2 example**
- **File**: `/home/brian/dev/marketstore/contrib/binancefeeder_v2/mkts.example.yml`

**K) Helm chart default config**
- **File**: `/home/brian/dev/marketstore/helm-chart/values.yaml` (lines 25-31)

```yaml
mktsConfig: |-
  root_directory: /data
  listen_port: 5993
  # grpc_listen_port: 5995
  timezone: UTC
  disable_variable_compression: true
```

---

### 2. Config Parsing Code - All Supported Configuration Keys

**File**: `/home/brian/dev/marketstore/utils/config.go`

The YAML is unmarshalled into the `aux` struct (lines 107-146), which defines the exact YAML key names via struct tags. These are then mapped to the `MktsConfig` struct (lines 45-65).

#### Complete YAML Key Reference

| YAML Key | Go Type | Default | Description |
|---|---|---|---|
| `root_directory` | string | **(required)** | Absolute or relative path to the data directory |
| `listen_host` | string | `""` (all interfaces) | Host to bind the HTTP/JSON-RPC server |
| `listen_port` | string | **(required)** | Port for JSON-RPC API (typically `5993`) |
| `grpc_listen_port` | string | `""` (disabled) | Port for gRPC API (typically `5995`) |
| `grpc_max_send_msg_size` | int | `1024` (MB) | Max gRPC send message size in MB |
| `grpc_max_recv_msg_size` | int | `1024` (MB) | Max gRPC recv message size in MB |
| `utilities_url` | string | `""` (disabled) | Enable pprof/heartbeat at this address (e.g. `localhost:5994`) |
| `timezone` | string | `"UTC"` | TZ database name (e.g. `America/New_York`) |
| `log_level` | string | `"info"` | One of: `fatal`, `error`, `warning`, `debug`, `info` |
| `stop_grace_period` | int | `0` | Seconds to wait after SIGINT before shutting down |
| `wal_rotate_interval` | int | `5` | WAL rotation frequency (multiplied by DiskRefreshInterval) |
| `disable_variable_compression` | string(bool) | `"false"` | Disable compression for variable-length data |
| `init_catalog` | string(bool) | `"true"` | Initialize catalog on startup |
| `init_wal_cache` | string(bool) | `"true"` | Initialize WAL cache on startup |
| `background_sync` | string(bool) | `"true"` | Enable background sync |
| `wal_bypass` | string(bool) | `"false"` | Bypass WAL (dangerous, for performance) |
| `replication` | object | (see below) | Replication settings |
| `triggers` | list | `[]` | Trigger plugin configurations |
| `bgworkers` | list | `[]` | Background worker plugin configurations |

Note: The boolean fields (`disable_variable_compression`, `init_catalog`, `init_wal_cache`, `background_sync`, `wal_bypass`) are parsed as strings and converted via `strconv.ParseBool`, so they accept `true`/`false`, `1`/`0`, `t`/`f`, etc.

#### Replication Sub-object

| YAML Key | Type | Default | Description |
|---|---|---|---|
| `replication.enabled` | bool | `false` | Enable as master (listens for replicas) |
| `replication.tls_enabled` | bool | `false` | Enable TLS for replication |
| `replication.cert_file` | string | `""` | TLS certificate file path |
| `replication.key_file` | string | `""` | TLS key file path |
| `replication.listen_port` | int | `5996` | Port master listens on for replicas |
| `replication.master_host` | string | `""` | Master host:port (set on replica to enable replica mode) |
| `replication.retry_interval` | duration | `10s` | Retry interval for replica reconnection |
| `replication.retry_backoff_coeff` | int | `2` | Backoff multiplier for retry |

#### Trigger Entry Structure

```yaml
triggers:
  - module: <filename.so>    # .so plugin file (looked up in $GOPATH/bin)
    on: "<glob pattern>"      # e.g. "*/1Min/OHLCV", "*/*/*"
    config:                   # passed as map[string]interface{} to NewTrigger()
      <key>: <value>
```

#### BgWorker Entry Structure

```yaml
bgworkers:
  - module: <filename.so>    # .so plugin file
    name: <display name>     # used for logging
    config:                  # passed as map[string]interface{} to NewBgWorker()
      <key>: <value>
```

---

### 3. `ondiskagg` Trigger Plugin (On-Disk Aggregation)

**Files**:
- README: `/home/brian/dev/marketstore/contrib/ondiskagg/README.md`
- Plugin shim: `/home/brian/dev/marketstore/contrib/ondiskagg/ondiskagg.go`
- Core implementation: `/home/brian/dev/marketstore/contrib/ondiskagg/aggtrigger/aggtrigger.go`

#### Purpose
Updates downsample (aggregate) data upon writes to the base timeframe. For example, when 1Min bars are written, it automatically computes and writes 5Min, 15Min, 1H, and 1D bars. Acts as a "materialized view" for time-series aggregation.

#### Config Struct (from `aggtrigger.go` lines 49-52)

```go
type Config struct {
    Destinations []string `json:"destinations"`
    Filter       string   `json:"filter"`
}
```

| Config Key | Type | Description |
|---|---|---|
| `destinations` | []string | Target timeframes to aggregate into (e.g. `5Min`, `15Min`, `1H`, `1D`) |
| `filter` | string | Only `"nasdaq"` is recognized -- filters 1D+ bars by NASDAQ market hours |

#### Supported Data Schema
Expects columns: `Open` (float32/float64), `High`, `Low`, `Close`, and optionally `Volume` (float32/float64/int32). Aggregation uses first(Open), max(High), min(Low), last(Close), sum(Volume).

#### Example Config

```yaml
triggers:
  - module: ondiskagg.so
    on: "*/1Min/OHLCV"
    config:
      filter: "nasdaq"
      destinations:
        - 5Min
        - 15Min
        - 1H
        - 1D
```

The `on` pattern `"*/1Min/OHLCV"` means: fire for any symbol, at 1Min timeframe, with OHLCV attribute group. The trigger also supports tick-to-bar aggregation when the base data uses the `TRADE` attribute group.

---

### 4. `massive` Background Worker Plugin

**Files**:
- README: `/home/brian/dev/marketstore/contrib/massive/README.md`
- Plugin main: `/home/brian/dev/marketstore/contrib/massive/massive.go`
- Config struct: `/home/brian/dev/marketstore/contrib/massive/massiveconfig/config.go`
- Example config: `/home/brian/dev/marketstore/contrib/massive/mkts.example.yml`

#### Purpose
Streams real-time market data via WebSocket from the Massive API, and optionally backfills historical data from the REST API on startup.

#### Config Struct (from `massiveconfig/config.go`)

```go
type FetcherConfig struct {
    APIKey            string   `json:"api_key"`
    BaseURL           string   `json:"base_url"`
    WSServer          string   `json:"ws_server"`
    DataTypes         []string `json:"data_types"`
    Symbols           []string `json:"symbols"`
    QueryStart        string   `json:"query_start"`
    BackfillBatchSize int      `json:"backfill_batch_size"`
    BackfillAdjusted  *bool    `json:"backfill_adjusted"`
}
```

| Config Key | Type | Default | Description |
|---|---|---|---|
| `api_key` | string | **(required)** | Massive API key |
| `base_url` | string | `https://api.massive.com` | REST API base URL |
| `ws_server` | string | `wss://socket.massive.com` | WebSocket server URL |
| `data_types` | []string | **(required)** | `bars`, `quotes`, `trades` |
| `symbols` | []string | `["*"]` | Symbols to subscribe (use `*` for all) |
| `query_start` | string | (none) | `YYYY-MM-DD` start date for backfill; omit to skip |
| `backfill_batch_size` | int | `50000` | REST API pagination limit |
| `backfill_adjusted` | bool | `true` | Whether bars are split-adjusted |

#### Example Config

```yaml
bgworkers:
  - module: massive.so
    name: Massive
    config:
      api_key: your_api_key
      ws_server: wss://socket.massive.com
      data_types: ["bars"]
      symbols:
        - AAPL
        - SPY
      query_start: "2024-01-01"
```

#### Other BgWorker Plugins Found

All follow the same `bgworkers` YAML pattern. Each plugin file and its `NewBgWorker` location:

| Plugin | File | Module Name |
|---|---|---|
| Massive | `/home/brian/dev/marketstore/contrib/massive/massive.go` | `massive.so` |
| Polygon | `/home/brian/dev/marketstore/contrib/polygon/polygon.go` | `polygon.so` |
| Alpaca | `/home/brian/dev/marketstore/contrib/alpaca/alpaca.go` | `alpaca.so` |
| AlpacaBkFeeder | `/home/brian/dev/marketstore/contrib/alpacabkfeeder/alpacav2.go` | `alpacabkfeeder.so` |
| IEX | `/home/brian/dev/marketstore/contrib/iex/iex.go` | `iex.so` |
| GdaxFeeder | `/home/brian/dev/marketstore/contrib/gdaxfeeder/gdaxfeeder.go` | `gdaxfeeder.so` |
| BitmexFeeder | `/home/brian/dev/marketstore/contrib/bitmexfeeder/bitmexfeeder.go` | `bitmexfeeder.so` |
| BinanceFeeder | `/home/brian/dev/marketstore/contrib/binancefeeder/binancefeeder.go` | `binancefeeder.so` |
| BinanceFeederV2 | `/home/brian/dev/marketstore/contrib/binancefeeder_v2/binancefeeder_v2.go` | `binancefeeder_v2.so` |
| XigniteFeeder | `/home/brian/dev/marketstore/contrib/xignitefeeder/xignitefeeder.go` | `xignitefeeder.so` |
| PolyIEX | `/home/brian/dev/marketstore/contrib/polyiex/polyiex.go` | `polyiex.so` |

---

### 5. How Triggers and BgWorkers Are Configured and Loaded

#### Plugin Interface Contracts

**Trigger** (from `/home/brian/dev/marketstore/plugins/trigger/trigger.go`):
```go
// Plugin must export:
func NewTrigger(config map[string]interface{}) (Trigger, error)

// Trigger interface:
type Trigger interface {
    Fire(keyPath string, records []Record)
}
```

**BgWorker** (from `/home/brian/dev/marketstore/plugins/bgworker/bgworker.go`):
```go
// Plugin must export:
func NewBgWorker(config map[string]interface{}) (BgWorker, error)

// BgWorker interface:
type BgWorker interface {
    Run()
}
```

#### Plugin Loading Flow

1. **Config parsed** (`utils/config.go` `ParseConfig()`): YAML triggers/bgworkers are parsed into `[]*TriggerSetting` and `[]*BgWorkerSetting` structs.

2. **Triggers loaded at startup** (`cmd/start/main.go` line 90): `c.GetStartTriggerPluginDispatcher()` initializes trigger matchers via `trigger.NewTriggerMatchers()` in `/home/brian/dev/marketstore/plugins/trigger/trigger.go`. Each trigger's `.so` file is loaded, the `NewTrigger` symbol is resolved, and called with the `config` map.

3. **BgWorkers loaded at startup** (`cmd/start/main.go` line 136): `RunBgWorkers(config.BgWorkers)` in `/home/brian/dev/marketstore/cmd/start/plugins.go`. For each bgworker, the `.so` file is loaded, the `NewBgWorker` symbol is resolved, called with the `config` map, and then `go bgWorker.Run()` is called.

4. **Trigger matching**: The `on` field uses glob-style matching (`*` = any non-slash segment). When data is written to a path like `AAPL/1Min/OHLCV/2024.bin`, it is matched against all trigger `on` patterns. Matching triggers have `Fire()` called.

#### Stream Trigger Plugin

**Files**:
- README: `/home/brian/dev/marketstore/contrib/stream/README.md`
- Plugin shim: `/home/brian/dev/marketstore/contrib/stream/stream.go`
- Implementation: `/home/brian/dev/marketstore/contrib/stream/streamtrigger/streamtrigger.go`

Config struct:
```go
type Config struct {
    Filter string `json:"filter"`
}
```

Only supports `filter: "nasdaq"` for filtering 1D+ bars by market hours. Example:

```yaml
triggers:
  - module: stream.so
    on: "*/*/*"
    config:
      filter: "nasdaq"
```

#### Plugin README

- **File**: `/home/brian/dev/marketstore/plugins/README.md` -- Documents both plugin interfaces and configuration patterns.

---

### Summary: All Relevant File Paths

| Category | File Path |
|---|---|
| **Config parser** | `/home/brian/dev/marketstore/utils/config.go` |
| **Startup/loader** | `/home/brian/dev/marketstore/cmd/start/main.go` |
| **BgWorker loader** | `/home/brian/dev/marketstore/cmd/start/plugins.go` |
| **Default YAML template** | `/home/brian/dev/marketstore/cmd/create/default.yml` |
| **Plugin interfaces** | `/home/brian/dev/marketstore/plugins/bgworker/bgworker.go` |
| **Plugin interfaces** | `/home/brian/dev/marketstore/plugins/trigger/trigger.go` |
| **Plugin README** | `/home/brian/dev/marketstore/plugins/README.md` |
| **ondiskagg README** | `/home/brian/dev/marketstore/contrib/ondiskagg/README.md` |
| **ondiskagg impl** | `/home/brian/dev/marketstore/contrib/ondiskagg/aggtrigger/aggtrigger.go` |
| **ondiskagg shim** | `/home/brian/dev/marketstore/contrib/ondiskagg/ondiskagg.go` |
| **stream README** | `/home/brian/dev/marketstore/contrib/stream/README.md` |
| **stream impl** | `/home/brian/dev/marketstore/contrib/stream/streamtrigger/streamtrigger.go` |
| **massive README** | `/home/brian/dev/marketstore/contrib/massive/README.md` |
| **massive impl** | `/home/brian/dev/marketstore/contrib/massive/massive.go` |
| **massive config struct** | `/home/brian/dev/marketstore/contrib/massive/massiveconfig/config.go` |
| **Example: massive** | `/home/brian/dev/marketstore/contrib/massive/mkts.example.yml` |
| **Example: polygon** | `/home/brian/dev/marketstore/contrib/polygon/mkts.example.yml` |
| **Example: iex** | `/home/brian/dev/marketstore/contrib/iex/mkts.example.yml` |
| **Example: alpaca** | `/home/brian/dev/marketstore/contrib/alpaca/mkts.example.yml` |
| **Example: binance v2** | `/home/brian/dev/marketstore/contrib/binancefeeder_v2/mkts.example.yml` |
| **Example: integ test** | `/home/brian/dev/marketstore/tests/integ/bin/mkts.yml` |
| **Example: repl master** | `/home/brian/dev/marketstore/tests/replication/config/mkts-master.yml` |
| **Example: repl replica** | `/home/brian/dev/marketstore/tests/replication/config/mkts-replica.yml` |
| **Example: test** | `/home/brian/dev/marketstore/test_config.yaml` |
| **Helm values** | `/home/brian/dev/marketstore/helm-chart/values.yaml` |
| **Helm configmap** | `/home/brian/dev/marketstore/helm-chart/templates/configmap.yaml` |
| **README options table** | `/home/brian/dev/marketstore/README.md` (lines 154-180) |
</task_result>
```

---

## Assistant (Build · claude-opus-4-6 · 23.3s)

Here's a `mkts.yml` that sets up the ondiskagg trigger to aggregate 1Min data into 1D bars, and runs the Massive background worker subscribing to minutely bars:

```yaml
root_directory: data
listen_port: 5993
grpc_listen_port: 5995
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
timezone: "America/New_York"

triggers:
  - module: ondiskagg.so
    on: "*/1Min/OHLCV"
    config:
      filter: "nasdaq"
      destinations:
        - 1D

bgworkers:
  - module: massive.so
    name: Massive
    config:
      api_key: "YOUR_API_KEY"
      base_url: "https://api.massive.com"
      ws_server: "wss://socket.massive.com"
      data_types:
        - bars
      symbols:
        - AAPL
        - SPY
      query_start: "2024-01-01"
      backfill_batch_size: 50000
      backfill_adjusted: true
```

Key points about this configuration:

- **`ondiskagg` trigger** — fires on any write matching `*/1Min/OHLCV` (any symbol, 1-minute timeframe, OHLCV schema). It aggregates into `1D` bars using first(Open), max(High), min(Low), last(Close), sum(Volume). The `filter: "nasdaq"` restricts 1D aggregation to NASDAQ market hours. If you want additional intermediate timeframes (5Min, 15Min, 1H), add them to `destinations`.

- **`massive` bgworker** — connects to the Massive WebSocket API and streams real-time minutely bars. On startup, it backfills historical data from `query_start` onward via the REST API. Replace `YOUR_API_KEY` with your actual API key, and adjust `symbols` to the tickers you want.

- **Other settings** — `timezone: "America/New_York"` aligns bar boundaries with US Eastern time. Ports 5993 (JSON-RPC) and 5995 (gRPC) are the defaults. Both `.so` plugin files need to be built first with `make plugins` and placed in `$GOPATH/bin`.

Remember to:
1. Replace `YOUR_API_KEY` with your actual Massive API key
2. Run `make plugins` to build the `ondiskagg.so` and `massive.so` shared objects
3. Adjust `symbols` to the tickers you want to track

---

---

## User

What is the development flow I should follow for
1. Run server
2. Test something
3. Make code changes
4. Repeat
I am running on fedora linux

---

## Assistant (Build · claude-opus-4-6 · 166.8s)

### `make install`
Same as `build` but uses `go install` so the binary goes to `$GOPATH/bin`.

### `make plugins`
Builds all 11 contrib plugins as Go shared objects (`.so` files) using `-buildmode=plugin`. Each plugin has its own Makefile in `contrib/<name>/Makefile`. Example from `/home/brian/dev/marketstore/contrib/ondiskagg/Makefile`:
```makefile
all:
	GOFLAGS=$(GOFLAGS) go build -o $(GOPATH0)/bin/ondiskagg.so -buildmode=plugin .
```

Plugins built by `make plugins`:
- `contrib/alpaca`
- `contrib/binancefeeder`
- `contrib/bitmexfeeder`
- `contrib/gdaxfeeder`
- `contrib/ice`
- `contrib/iex`
- `contrib/ondiskagg`
- `contrib/polygon`
- `contrib/stream`
- `contrib/xignitefeeder`
- `contrib/alpacabkfeeder`

### `make debug`
Builds all plugins and the main binary with debug symbols (`-gcflags="all=-N -l"`), suitable for use with `dlv` or similar debuggers.

### Other build targets
- **`make fmt`** -- Runs `go fmt ./...`
- **`make generate`** -- Runs `go generate` on all files with `//go:generate` directives
- **`make generate-sql`** -- Rebuilds the ANTLR-based SQL parser in `sqlparser/`
- **`make update`** -- Runs `go mod tidy`

---

## 3. Project Entrypoint and CLI Structure

### Entrypoint
**File:** `/home/brian/dev/marketstore/marketstore.go`

```go
package main

import (
    "os"
    "github.com/alpacahq/marketstore/v4/cmd"
)

func main() {
    if err := cmd.Execute(); err != nil {
        os.Exit(0)
    }
}
```

### Root Command (Cobra)
**File:** `/home/brian/dev/marketstore/cmd/main.go`

The root command is `marketstore`. It registers 5 subcommands and a `--version` / `-v` flag:

| Subcommand | Use | Description | File |
|---|---|---|---|
| `start` (alias: `s`) | `marketstore start --config <path>` | Start the database server | `/home/brian/dev/marketstore/cmd/start/main.go` |
| `connect` | `marketstore connect --url <host:port>` | Open interactive client session | `/home/brian/dev/marketstore/cmd/connect/main.go` |
| `init` | `marketstore init` | Create a default `mkts.yml` config file | `/home/brian/dev/marketstore/cmd/create/main.go` |
| `estimate` | `marketstore estimate --symbols 5000 --timeframe 1Sec --years 5` | Estimate required storage space | `/home/brian/dev/marketstore/cmd/estimate/main.go` |
| `tool` | `marketstore tool <subcommand>` | Execute diagnostic tools | `/home/brian/dev/marketstore/cmd/tool/main.go` |

The `tool` command has two sub-subcommands:
- **`wal`**: `marketstore tool wal --file <path>` -- Examine a WAL file's unwritten transactions (`/home/brian/dev/marketstore/cmd/tool/wal/main.go`)
- **`integrity`**: `marketstore tool integrity --dir <path> --fix --parallel` -- Evaluate checksums on database internals (`/home/brian/dev/marketstore/cmd/tool/integrity/main.go`)

---

## 4. Running the Server (`marketstore start`)

**File:** `/home/brian/dev/marketstore/cmd/start/main.go`

### Command
```bash
marketstore start --config ./mkts.yml
```

### What it does (in order):
1. Reads the YAML config file (default: `./mkts.yml`)
2. Parses config via `utils.ParseConfig()`
3. Initializes dependency injection container (`internal/di`)
4. Starts replication sender (if configured as master)
5. Starts trigger plugin dispatcher
6. Initializes the database engine (`executor.NewInstanceSetup`)
7. Starts disk usage monitoring (every 10 minutes)
8. Initializes replication client (if configured as replica)
9. Registers gRPC server
10. Sets up HTTP handlers: `/rpc` (JSON-RPC), `/ws` (WebSocket streaming), `/metrics` (Prometheus)
11. Loads and runs background worker plugins (from `bgworkers` config section)
12. Optionally starts utility/pprof endpoints
13. Starts gRPC listener (if `grpc_listen_port` configured)
14. Starts HTTP listener for JSON-RPC
15. Handles signals: `SIGUSR1` (dump goroutines), `SIGINT`/`SIGTERM` (graceful shutdown)

### Default Config
**File:** `/home/brian/dev/marketstore/cmd/create/default.yml`

```yaml
root_directory: data
listen_port: 5993          # JSON-RPC API
grpc_listen_port: 5995     # gRPC API
log_level: info
stop_grace_period: 0
wal_rotate_interval: 5
```

### Background Worker Plugins
**File:** `/home/brian/dev/marketstore/cmd/start/plugins.go`

Plugins are loaded as `.so` shared objects via `plugins.NewSymbolLoader()` and started as goroutines.

---

## 5. The `connect` Interactive Client

**Files:**
- `/home/brian/dev/marketstore/cmd/connect/main.go` -- Command definition
- `/home/brian/dev/marketstore/cmd/connect/session/client.go` -- REPL loop and command dispatch
- `/home/brian/dev/marketstore/cmd/connect/session/help.go` -- Help text for all commands
- `/home/brian/dev/marketstore/cmd/connect/session/show.go` -- `\show` command
- `/home/brian/dev/marketstore/cmd/connect/session/create.go` -- `\create`, `\destroy`, `\getinfo`
- `/home/brian/dev/marketstore/cmd/connect/session/load.go` -- `\load` (CSV import)
- `/home/brian/dev/marketstore/cmd/connect/session/trim.go` -- `\trim` (local mode only)
- `/home/brian/dev/marketstore/cmd/connect/session/sql.go` -- SQL query execution
- `/home/brian/dev/marketstore/cmd/connect/loader/` -- CSV reading/writing utilities

### Two modes:
1. **Remote mode:** `marketstore connect --url hostname:port` -- connects via JSON-RPC
2. **Local mode:** `marketstore connect --dir /path/to/mktsdb` -- opens database files directly

### Interactive commands (readline-based REPL with history at `~/.marketstoreReaderHistory`):

| Command | Description |
|---|---|
| `\show <Symbol/TF/Attr> <start> [<end>]` | Display data in date range |
| `\create <full-key> <data-shape> <row-type>` | Create a new bucket |
| `\destroy <key>` | Remove a bucket |
| `\getinfo <key>` | Show bucket metadata (datashape, timeframe, record type) |
| `\load <key> <csv> [<yaml>]` | Load CSV data into a bucket |
| `\trim <key> <date>` | Zero out data from date onward (local mode only) |
| `\o <filepath>` | Redirect output to a file |
| `\timing` | Toggle query timing display |
| `\help <command>` or `\?` | Show help |
| `\quit`, `\q`, `\stop`, `exit` | Exit |
| Any other input | Treated as a SQL query |

### Example session:
```
marketstore connect --url localhost:5993
>> \show TSLA/1Min/OHLCV 2016-09-15T13:30
>> \create TEST/1D/TICK:Symbol/Timeframe/AttributeGroup Bid,Ask/float32 variable
>> \load TEST/1D/TICK data.csv loader.yaml
>> SELECT * FROM `TSLA/1Min/OHLCV` WHERE Epoch > '2020-01-01'
>> \q
```

---

## 6. Running Tests

### Unit tests
```bash
make unit-test
# Runs: go test -coverprofile=coverage.txt -covermode=atomic ./...
```
Note: The `-race` flag is intentionally disabled because `contrib/stream/shelf/shelf_test.go` fails with it.

### Single package tests
```bash
go test ./executor/...
go test ./catalog/... -run TestName
go test -v ./frontend/... -run TestQuery
```

### Coverage for a single package
**File:** `/home/brian/dev/marketstore/scripts/coverage.sh`
```bash
go test -coverprofile data/coverage $1 && go tool cover -html=data/coverage
# Usage: scripts/coverage.sh ./executor/...
```

### CSV Import test (requires built binary)
```bash
make import-csv-test
# Runs: tests/integ/bin/runtests.sh
```
This script (`/home/brian/dev/marketstore/tests/integ/bin/runtests.sh`) uses the built `marketstore` binary in local mode to test CSV import/export with `\create`, `\load`, `\show`, and `\o` commands, comparing output against expected CSV files.

### Integration tests (require Docker)
```bash
make integration-test-jsonrpc    # Python pytest via Docker, JSON-RPC API
make integration-test-grpc       # Python pytest via Docker, gRPC API
make integration-test-contrib    # Tests contrib/ice plugin
make replication-test            # Master-replica replication test
```

### Full test suite
```bash
make test    # build + unit-test + import-csv-test + integration-test-jsonrpc + integration-test-grpc + integration-test-contrib
```

---

## 7. How Integration Tests Work

### Architecture
Integration tests use a 2-container Docker setup:

1. **MarketStore server container** -- Built from the project's root `Dockerfile`, runs with a test config
2. **Python client container** -- Built from `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/Dockerfile`, uses `pymarketstore` library and `pytest`

**Key files:**
- `/home/brian/dev/marketstore/tests/integ/Makefile` -- Orchestration
- `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/Dockerfile` -- Python test client image (based on Miniconda)
- `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/requirements.txt` -- `pytest==3.6.1` + `pymarketstore` from git
- `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/Makefile` -- Commands to run tests inside container
- `/home/brian/dev/marketstore/tests/integ/dockerfiles/Makefile.common` -- Shared Docker helpers
- `/home/brian/dev/marketstore/tests/integ/bin/mkts.yml` -- Test server configuration

### Test flow for `make integration-test-jsonrpc`:
1. `clean` -- Stop/remove any existing containers, clean data
2. `build_mstore` -- `docker build` from root Dockerfile, tagged as `alpacahq/integrationtests.marketstore`
3. `run` -- Create container, copy test config + data, start marketstore with `start --config /project/bin/mkts.yml`
4. `_start_pyclient_container` -- Build + run the Python client container
5. `connect` -- Verify connectivity via a `ListSymbols` JSON-RPC call
6. Run `pytest` inside the Python container against `/project/tests/test-jsonrpc.py`
7. Run `cli_remote_test.sh` inside the marketstore container (tests remote CLI commands)

### Test files (26 Python test files):
Located in `/home/brian/dev/marketstore/tests/integ/tests/`:
- `test_ticks.py`, `test_ticks_1sec_timeframe.py`, `test_ticks_fields_and_types.py`
- `test_list_symbols.py`, `test_symbols_name.py`
- `test_query_limits.py`, `test_query_multi_symbols.py`, `test_query_overlapping_years.py`
- `test_data_integrity.py`, `test_nanoseconds_precision.py`, `test_range_nanosec.py`
- `test_create.py`, `test_string16.py`, `test_basic_aggfunc.py`, `test_aggcandler.py`
- `test_coerce_column.py`, `test_overflow_query.py`, `test_grpc_compat.py`
- And more...

Environment variables control which API to test:
- `MARKETSTORE_PORT=5993` + `USE_GRPC=false` for JSON-RPC
- `MARKETSTORE_PORT=5995` + `USE_GRPC=true` for gRPC

### Replication tests
**File:** `/home/brian/dev/marketstore/tests/replication/Makefile`

Uses 3 Docker containers:
1. **Master** (ports 5996/5997/5998) -- config at `/home/brian/dev/marketstore/tests/replication/config/mkts-master.yml`
2. **Replica** (ports 5999/6000) -- config at `/home/brian/dev/marketstore/tests/replication/config/mkts-replica.yml`
3. **pymarketstore client** -- runs pytest against master/replica

All containers join a `marketstore` Docker network. The replica connects to `replication_tests_mstore_master:5998`.

---

## 8. Docker Files

### Main Dockerfile
**File:** `/home/brian/dev/marketstore/Dockerfile`

Two-stage build:
- **Stage 1:** `golang:1.18.1-buster` -- builds binary and optionally plugins (`INCLUDE_PLUGINS=true` by default)
- **Stage 2:** `debian:10.3` -- minimal runtime image with the binary

The container runs `marketstore start --config /etc/mkts.yml` by default, exposing port 5993.

### Docker-related Makefile targets:
```bash
make image            # docker build . -t marketstore:latest
make runimage         # Start test image
make stopimage        # Stop test image
make push             # Build + push to Docker Hub (alpacamarkets/marketstore)
```

### No docker-compose files exist
There are no `docker-compose.yml` files anywhere in the project. All multi-container orchestration is done via Makefile targets with raw `docker` commands.

---

## 9. Hot-Reload / Watch Mode

**There is no hot-reload or watch mode.** There are no references to tools like `air`, `reflex`, `entr`, or any file-watching mechanism in the codebase. You must rebuild manually after code changes:

```bash
make build    # rebuild binary
# then restart the server
```

For plugins, you also need to rebuild them:
```bash
make plugins
```

---

## 10. Complete Makefile Contents

**File:** `/home/brian/dev/marketstore/Makefile` (92 lines)

```makefile
.PHONY: plugins

GOFLAGS=""
GOPATH0 := $(firstword $(subst :, ,$(GOPATH)))
UTIL_PATH := github.com/alpacahq/marketstore/v4/utils

build:
	GOFLAGS=$(GOFLAGS) go build -ldflags "-s -X $(UTIL_PATH).Tag=$(DOCKER_TAG) -X $(UTIL_PATH).BuildStamp=$(shell date -u +%Y-%m-%d-%H-%M-%S) -X $(UTIL_PATH).GitHash=$(shell git rev-parse HEAD)" .

install:
	GOFLAGS=$(GOFLAGS) go install -ldflags "-s -X $(UTIL_PATH).Tag=$(DOCKER_TAG) -X $(UTIL_PATH).BuildStamp=$(shell date -u +%Y-%m-%d-%H-%M-%S) -X $(UTIL_PATH).GitHash=$(shell git rev-parse HEAD)" .

debug:
	$(MAKE) debug -C contrib/alpaca
	$(MAKE) debug -C contrib/binancefeeder
	$(MAKE) debug -C contrib/bitmexfeeder
	$(MAKE) debug -C contrib/gdaxfeeder
	$(MAKE) debug -C contrib/ice
	$(MAKE) debug -C contrib/iex
	$(MAKE) debug -C contrib/ondiskagg
	$(MAKE) debug -C contrib/polygon
	$(MAKE) debug -C contrib/stream
	$(MAKE) debug -C contrib/xignitefeeder
	GOFLAGS=$(GOFLAGS) go install -gcflags="all=-N -l" -ldflags "-X $(UTIL_PATH).Tag=$(DOCKER_TAG) -X $(UTIL_PATH).BuildStamp=$(shell date -u +%Y-%m-%d-%H-%M-%S) -X $(UTIL_PATH).GitHash=$(shell git rev-parse HEAD)" ./...

generate:
	GOFLAGS=$(GOFLAGS) go generate $(shell find . -path ./vendor -prune -o -name \*.go -exec grep -q go:generate {} \; -print | while read file; do echo `dirname $$file`; done | xargs)

generate-sql:
	make -C sqlparser

update:
	GOFLAGS=$(GOFLAGS) go mod tidy

plugins:
	$(MAKE) -C contrib/alpaca
	$(MAKE) -C contrib/binancefeeder
	$(MAKE) -C contrib/bitmexfeeder
	$(MAKE) -C contrib/gdaxfeeder
	${MAKE} -C contrib/ice
	$(MAKE) -C contrib/iex
	$(MAKE) -C contrib/ondiskagg
	$(MAKE) -C contrib/polygon
	$(MAKE) -C contrib/stream
	$(MAKE) -C contrib/xignitefeeder
	$(MAKE) -C contrib/alpacabkfeeder

fmt:
	GOFLAGS=$(GOFLAGS) go fmt ./...

unit-test:
	# marketstore/contrib/stream/shelf/shelf_test.go fails if "-race" enabled...
	# GOFLAGS=$(GOFLAGS) go test -race -coverprofile=coverage.txt -covermode=atomic ./...
	GOFLAGS=$(GOFLAGS) go test -coverprofile=coverage.txt -covermode=atomic ./...

import-csv-test:
	@tests/integ/bin/runtests.sh

integration-test-jsonrpc:
	$(MAKE) -C tests/integ test-jsonrpc

integration-test-grpc:
	$(MAKE) -C tests/integ test-grpc

integration-test-contrib:
	$(MAKE) -C tests/integ test-contrib

replication-test:
	$(MAKE) -C tests/replication test-replication

test: build
	$(MAKE) unit-test
	$(MAKE) import-csv-test
	$(MAKE) integration-test-jsonrpc
	$(MAKE) integration-test-grpc
	$(MAKE) integration-test-contrib

image:
	docker build . -t marketstore:latest -f $(DOCKER_FILE_PATH)

runimage:
	make -C tests/integ run IMAGE_NAME=alpacamarkets/marketstore.test

stopimage:
	make -C tests/integ clean IMAGE_NAME=alpacamarkets/marketstore.test

push:
	docker build --build-arg tag=$(DOCKER_TAG) -t alpacamarkets/marketstore:$(DOCKER_TAG) -t alpacamarkets/marketstore:latest .
	docker login -u $(DOCKER_USER) -p $(DOCKER_PASS)
	docker push alpacamarkets/marketstore:$(DOCKER_TAG)
	docker push alpacamarkets/marketstore:latest
```

---

## Summary: Quick-Start Development Workflow

```bash
# 1. Build the binary
make build

# 2. Initialize a config file
./marketstore init          # creates mkts.yml in current dir

# 3. Start the server
./marketstore start --config ./mkts.yml

# 4. Connect interactively (in another terminal)
./marketstore connect --url localhost:5993

# 5. Run unit tests
make unit-test

# 6. Run a single package test
go test -v ./executor/... -run TestName

# 7. Run integration tests (needs Docker)
make integration-test-jsonrpc

# 8. Build with plugins
make build plugins

# 9. Check version
./marketstore -v
```

### All relevant file paths referenced:

| File | Purpose |
|---|---|
| `/home/brian/dev/marketstore/Makefile` | Root build system |
| `/home/brian/dev/marketstore/go.mod` | Go module definition (Go 1.18) |
| `/home/brian/dev/marketstore/marketstore.go` | Binary entrypoint (`package main`) |
| `/home/brian/dev/marketstore/cmd/main.go` | Cobra root command, registers subcommands |
| `/home/brian/dev/marketstore/cmd/start/main.go` | `start` command -- server startup |
| `/home/brian/dev/marketstore/cmd/start/plugins.go` | Background worker plugin loader |
| `/home/brian/dev/marketstore/cmd/connect/main.go` | `connect` command -- interactive client |
| `/home/brian/dev/marketstore/cmd/connect/session/client.go` | REPL loop and command dispatch |
| `/home/brian/dev/marketstore/cmd/connect/session/help.go` | Help text for interactive commands |
| `/home/brian/dev/marketstore/cmd/connect/session/show.go` | `\show` command implementation |
| `/home/brian/dev/marketstore/cmd/connect/session/create.go` | `\create`, `\destroy`, `\getinfo` commands |
| `/home/brian/dev/marketstore/cmd/connect/session/load.go` | `\load` CSV import command |
| `/home/brian/dev/marketstore/cmd/connect/session/trim.go` | `\trim` command (local mode) |
| `/home/brian/dev/marketstore/cmd/connect/session/sql.go` | SQL query execution |
| `/home/brian/dev/marketstore/cmd/create/main.go` | `init` command -- creates mkts.yml |
| `/home/brian/dev/marketstore/cmd/create/default.yml` | Default configuration template |
| `/home/brian/dev/marketstore/cmd/estimate/main.go` | `estimate` command -- storage calculator |
| `/home/brian/dev/marketstore/cmd/tool/main.go` | `tool` command -- parent for wal/integrity |
| `/home/brian/dev/marketstore/cmd/tool/wal/main.go` | WAL file debugger |
| `/home/brian/dev/marketstore/cmd/tool/integrity/main.go` | Database integrity checker |
| `/home/brian/dev/marketstore/Dockerfile` | Multi-stage Docker build |
| `/home/brian/dev/marketstore/tests/integ/Makefile` | Integration test orchestration |
| `/home/brian/dev/marketstore/tests/integ/README.md` | Integration test documentation |
| `/home/brian/dev/marketstore/tests/integ/bin/mkts.yml` | Test server configuration |
| `/home/brian/dev/marketstore/tests/integ/bin/runtests.sh` | CSV import test script |
| `/home/brian/dev/marketstore/tests/integ/bin/cli_remote_test.sh` | Remote CLI integration tests |
| `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/Dockerfile` | Python test client Docker image |
| `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/Makefile` | Python test runner |
| `/home/brian/dev/marketstore/tests/integ/dockerfiles/pyclient/requirements.txt` | Python test dependencies |
| `/home/brian/dev/marketstore/tests/integ/dockerfiles/Makefile.common` | Shared Docker Makefile helpers |
| `/home/brian/dev/marketstore/tests/replication/Makefile` | Replication test orchestration |
| `/home/brian/dev/marketstore/tests/replication/config/mkts-master.yml` | Replication master config |
| `/home/brian/dev/marketstore/tests/replication/config/mkts-replica.yml` | Replication replica config |
| `/home/brian/dev/marketstore/contrib/ondiskagg/Makefile` | Example plugin Makefile |
| `/home/brian/dev/marketstore/scripts/coverage.sh` | Per-package coverage helper |
| `/home/brian/dev/marketstore/.circleci/config.yml` | CI/CD pipeline definition |
</task_result>
```

---

## Assistant (Build · claude-opus-4-6 · 16.4s)

Here's the development loop for MarketStore on Fedora:

## Prerequisites

Make sure you have Go 1.18 installed. On Fedora:

```bash
# Check your Go version
go version

# If you need Go 1.18 specifically (the project requires it)
sudo dnf install golang   # or use goenv/asdf for version management
```

## The Development Loop

### 1. Initial build (binary + plugins)

```bash
make build && make plugins
```

This puts the `marketstore` binary in the project root and `.so` plugin files in `$GOPATH/bin/`.

### 2. Start the server

```bash
./marketstore start --config ./mkts.yml
```

Leave this running in a terminal. It listens on `:5993` (JSON-RPC) and `:5995` (gRPC).

### 3. Test interactively

Open a second terminal:

```bash
# Connect to the running server
./marketstore connect --url localhost:5993

# Inside the REPL:
>> \show AAPL/1Min/OHLCV 2024-01-01
>> \show AAPL/1D/OHLCV 2024-01-01
>> SELECT * FROM `AAPL/1Min/OHLCV` WHERE Epoch > '2024-01-01'
>> \getinfo AAPL/1D/OHLCV
>> \q
```

### 4. Run unit tests

```bash
# All unit tests
make unit-test

# Single package
go test ./executor/...

# Single test by name (verbose)
go test -v ./frontend/... -run TestQuery
```

### 5. Make code changes, rebuild, restart

```bash
# Stop the server (Ctrl+C in the server terminal), then:

# If you changed core code only:
make build

# If you changed plugin code (ondiskagg, stream, massive, etc.):
make plugins

# If you changed both:
make build && make plugins

# Restart
./marketstore start --config ./mkts.yml
```

There's no hot-reload -- you must stop, rebuild, and restart manually each time.

### 6. Integration tests (requires Docker)

```bash
make integration-test-jsonrpc   # JSON-RPC API tests
make integration-test-grpc      # gRPC API tests
```

## Quick Reference

| Task | Command |
|---|---|
| Build everything | `make build && make plugins` |
| Start server | `./marketstore start --config ./mkts.yml` |
| Interactive client | `./marketstore connect --url localhost:5993` |
| Unit tests | `make unit-test` |
| One package | `go test -v ./catalog/... -run TestName` |
| Integration tests | `make integration-test-jsonrpc` |
| Format code | `make fmt` |
| Debug build (for dlv) | `make debug` |
| Check data integrity | `./marketstore tool integrity --dir ./data` |
| Inspect WAL | `./marketstore tool wal --file ./data/WALFile.1` |

The typical inner loop is: **stop server -> `make build` -> start server -> test with `connect`**. Keep two terminals open -- one for the server, one for building/testing.

---
